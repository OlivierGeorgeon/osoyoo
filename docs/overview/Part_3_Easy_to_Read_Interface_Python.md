
##



# PETITCAT PROJECT DISCLAIMER

**Date:** July 1, 2024

This is a public document that can be modified by others who have access. If anything doesn't make sense, please ignore it. Original contributors may not be aware of the full contents of this document or what is still current over time.

**Safety Notice:**
No use of high voltage or anything dangerous is or should be specified in this document. Any illustrations are or should be contributors' own, generated by ethical generative software and modified by themselves, or taken from open technical sites. No unethical content should be included. 

**Copyright and Fair Use:**
Reproduction is limited to "fair use" or otherwise not allowed if prohibited by law. Software, documentation, and logo belong to (c) and (tm) the PetitCat project and creators but are allowed for "fair use" or otherwise not allowed if prohibited by law. Usage is "as is"â€”users should consider and treat this project as experimental.

**Project Nature:**
This is a multiple-person open-source GitHub project. Note that this project is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the license indicated on the GitHub site for more information. If no license is specified, then by default the MIT License or the Apache-2 License applies:
- [MIT License](https://opensource.org/licenses/MIT)
- [Apache License](https://opensource.org/licenses/Apache-2.0)

**Content and Contributions:**
All content included in this project, such as code, documentation, and related materials, should be created by the contributors of this project or should be open-source software components. To the best of our knowledge, all content complies with copyright laws and is either original or used with permission. If any content should not be here, please advise, and a correction will be made in a suitable time period. Note that material in this project can be modified by members of the public once they join the project, and other members are not responsible for changes by one member.

**Patent Disclaimer:**
We, the contributors of this project, do not provide any warranty or guarantee that the use, distribution, or modification of this project does not infringe on any patents. It is the responsibility of the user or distributor of this project to ensure compliance with any applicable patent laws. This project should be used for non-commercial purposes only.

**Liability:**
By using this project, you agree that you are solely responsible for any legal issues or liabilities that may arise. The contributors of this project shall not be held liable for any direct, indirect, incidental, or consequential damages arising from the use, distribution, or modification of this project. Do NOT use this project for any mission-critical (including any health) projects.

**Contributions:**
If you contribute to this project, you assert that your contributions are given freely and are your original work and do not violate any third-party copyrights, patents, or other intellectual property rights. You grant permission for your contributions to be used in this project under the project's open-source license.

**Contact:**
If any content should not be here or if there are any legal concerns, please advise, and a correction will be made in a suitable time period.


##



# An Easy-to-Read Overview of the Robot Car ("PetitCat") Project
# Part III

![petitcatgpt4logo](petitcatgpt4logo.jpg)
-
 
-

<h2 style="font-size: 24px;">The PetitCat Project </h2>

---------------

Step by step explanations for beginners and researchers alike. The documentation is intended to give any user a pleasant experience with the project regardless of how seriously they intend to make use of the project. An issue for many researchers in using GitHub software is that it more often fails to work (or work properly) mainly because the thousands of litte things in the heads of the developers are not made clear to the non-involved user. Here we have gone to the other extreme, to make sure that the hardware and software will work for any user, although the more advanced topics are geared towards researchers rather than students. We have paid much attention to the main causes of poor GitHub and other open source software usability: incomplete documentation, dependency issues, environment configuration, version mismatches, non-graceful error handling, permissions and access, network/connectivity issues, stability, indadequate testing, user prerequisite knowledge. Easy-to-read, guaranteed-to-work and inexpensive may surprise you in producing an example of a superhuman AGI with robotic embodiment.

----------------


The "Easy-to-Read Overview" of the project is divided into a number of parts:

**Part I:** The Basics: Assembly, Software and Using

**Part II:** Modifying the Robot Car for Python Control

**Part III:** Interfacing your Python Code with the PetitCat Project

**Part IV:** Modifying the C/C++ for your Selected Robotic Embodiment

**Part V:** Integration of PetitCat with a Causal Cognitive Architecture

**Part VI:** Integration of PetitCat with a Large Language Model

**Part VII:** Active Inference of the Robot Car


The PetitCat documentation is written so that anyone with a basic education can read it and understand it. Having a deeper breadth of knowledge in software development, AI, or cognitive science, can, of course, allow greater appreciation for certain aspects of the project.

-Part I does not require any specialized background knowledge. You should be familiar with moving files around in either your Windows, Mac or Linux desktop/laptop computer. Other than that, no specialized knoweldge is needed. Part I is perfectly fine for high school students and hobbyists.

-Part II may be fine for high school students, college students and hobbyists as well, given a willingness of some effort to learn things here and there. However, the documentation will guide you on this learning journey. The lower level software of the PetitCat project is written in C\C++ in the Arduino IDE. You don't need to know these languages or environment in order to use Python with the project. However, we provide a very basic C\C++\Arduino tutorial which may be sufficient for most readers who do want to have a bit more control over the Arduino board coding. We just touch upon the Python control of the project at the end of Part II, so you are not expected to have much Python knowledge in this part, unless you want to start modifying the Python files.

-Part III is where the PetitCat project becomes more useful -- interfacing the Python code of your AI/AGI project with the PetitCat projects.

-Part IV allows you to modify the Arduino C/C++ code to use other robotic embodiments than the default robot car, or to add addtional sensors and actuators to the robot car.

-In Parts V and VI we will integrate the PetitCat project with a cognitive architecture and then a large language model. Again, in this part, only intermediate (or even novice) Python coding abilities are required. However, we will gently guide you through the project, so that you end up with a super-human intelligent grounded autonomous robot system.

-Part VII really only requires some knowledge of Python. You do not have to be an expert developer. More important, is perhaps a background in AI or cognitive science. However, there is no real background prerequisite here. Regardless of the reader's background, we provide gentle tutorials on a number of topics, and guide the learner through the concepts of active inference and implementing it in the PetitCat project.

-



# Part III: Interfacing your Python Code with the PetitCat Project

-
-

<h1 style="font-size: 24px;">Step #1 -- Time to Get Serious</h1>

Regardless of your skill level, you have made it this far -- you have built a robot car with your hands, you have learned how to move software around (Part I) and then you learned how to write some software in C/C++, build electronic circuits and make the software control the electronics (Part II). 

In Part I you became familiar with the hardware and software systems we are using. In Part II you developed more experience with the software and you transitioned from the Osoyoo pre-canned demonstration programs to a more serious use of the robot car. If you are an experienced researcher then this was largely a review of material you knew, albeit applied to a slightly different software/hardware environment. If you are student then this was an opportunity to learn a wide range of subject material that will benefit you regardless of your future endeavors.

At this point your robot car should be controllable from Python code running on your desktop/laptop. If not, then please go back to the previous Part II and make sure it is working, before continuing in this Part III. (Actually in the next Step we will verify this!!)

Ok... you successfully completed Part II and have a robot car you can control from your Python code. Now here you are. In this Part III we will start doing a bit more serious work. But, regardless of your skill level or experience, do not worry -- this manual will gently guide you through the steps.

In this Part III we will explore a bit more the software we just finished compiling and installing in Part II. We will transition to a Python module which you can use with your existing AI/AGI software, albeit, Python code. Thus, you will readily have a grounded embodiment for your AI/AGI code with a very reasonable learning curve. If you are a student and don't have pre-existing AI/AGI software, then we will create some. (In future parts you will be provided with the source code for a full cognitive architecture and can interface that code to the robotic car or other robotic embodiment you are using.)

You made it this far, and you will succeed again in this part.  Get on that horse. Saddle up!!  


<p align="center">
 <img src="horsetonextlesson.png" width="570" height="570">
</p>
-

-

<h1 style="font-size: 24px;">Step #2 -- Review of the Project Hardware and Software </h1>

In the 1950s a Japanese educator, Toru Kumon, developed a method to enable his own son to progress more rapidly through mathematics. In 1958 the Kumon Math teaching system was established and proved very successful compared to typical public school teaching methods in mathematics.

Ironically, the Kumon system focused on methods which are antithetical to the principles of mathematics -- memorization and review. However, the reality is that memorization and review of the foundational mathematical facts and procedures seem to work best for the human brain to then be in a stronger position to appreciate the true essence of the subject, i.e., discovering methods and theories, problem solving, logical reasoning and critical thinking.  And so, in this spirit, let's very quickly review the previous two parts in terms of the performance of the robotic car.

<h1 style="font-size: 24px;">i : Does Basic Robotic Car and Wi-Fi Control Work? </h1>

-Open the Arduino IDE.

-Click 'Open' and load in m2-lesson5b.ino 

-Then attach the USB cable to the Arduino board connector on the robot car.

-You may now need to tell the software what your Wi-Fi SSID and password are (if this isn't already there from Part II).

For example, if the name of the network you log into is "Jones" then your SSID is "Jones" and if the password to log into your Wi-Fi is "test1234" then your password is "test1234".

--> Look at lines 180 and 181 (or equivalent lines if the software has changed since the time of this writing).  Modify the lines as follows:

char ssid[] = "Jones"

char pass[] = "test1234"

![ssid](ssid.png)



-Now click the upload arrow (green arrow inside a circle at the top left corner).

-The software in m2-lesson5b.ino (modified with your Wi-Fi SSID and password) will now be uploaded to the Arduino board in your robotic car.

![lesson5b](lesson5b.png)



-Now open the Serial Monitor on the Arduino IDE. You will see something like this written:

![ipconnected](ipconnected.png)

Write down the IP address you, in this example, it would be "10.0.0.41" -- you will need this address for the App running on your smartphone -- it will tell the App where the robot car is connected.


--Phone APP software--

You have already downloaded the phone app in Part I and Part II. 

In case you did not do this or you un-installed the app from your phone:

-If you have an Apple phone then you will go to the Apple Store

-However, since I have an Android phone (Pixel 7) I will go to the Google Play store

-The Osoyoo Manual Lesson 5 advises to search "Osoyoo Wifi UDP Robot Car Controller"

-Unfortunately when I do this search (Feb 9, 2024) the only app that appears in the Google Play store is "Osoyoo IoT UDP Robot APP" -- well, better than nothing, and maybe it will do the same thing.... so this app is installed on my Android cellphone


---> Your smartphone App is installed. (Whether it is called "Osoyoo Wifi UDP Robot Car Controller" or "Osoyoo IoT UDP Robot APP").

Now we have to go to the settings section of the phone App.

-Ok we open the Osoyoo IoT UDP Robot APP

-Then go to Settings and enter the IP address we saw in the Serial Monitor. In this example, we would enter "10.0.0.41" (you will enter, of course, the IP address your Serial Monitor showed you -- this is the address the robot car is using).

-You can leave the other settings such as the default Ports unchanged

Your smartphone App should now be able to control your robot car. Let's try it out.

-Ok...now go to the main page of the app.

![appsmall](appsmall.png)

-Ok... turn on the robot car

-Now, let's click a button on the app.... go forward

The car goes forward.

Click backwards, left and right.

They all work .... we can control the robot car via Wi-Fi. Note that both the robot car and cellphone are attached to the same house/workplace Wi-Fi router.

(If this does not work, then go back to Parts 1 and 2 to troubleshoot any issues you may be having with your hardware, software or Wi-Fi environment.)

<p align="center">
 <img src="wifiworks.jpg" width="250" height="250">
</p>

-

<h1 style="font-size: 24px;">ii : Does Robotic Car and Python Wi-Fi Control Work? </h1>

If you recall from Part II, the arduino_secrets.h file contains your home (or workplace) Wi-Fi identifying information and login password, hence its name and why it is kept separate from the other files in the GitHub repository.

--> You should have already copied "arduino_secrets.h" to \src\wifi of your Arduino PetitCat project. If not follow the steps below:

-------------------
(On my computer the Arduino Sketchbook is c:\Users\howar\OneDrive\Documents\Arduino. The full path to the wifi subfolder on my computer is : c:\Users\howar\OneDrive\Documents\Arduino\petitcat_arduino\src\wifi  -- your computer will have a different path, but it will also end with "\petitcat_arduino\src\wifi")

--> If you don't have a file "arduino_secrets.h" in the \src\wifi subfolder of your Arduino PetitCat project, then take a look again at Part II, or else just use any text or programmming editor to create a file "arduino_secrets.h" containing the following lines:

<b>#define SECRET_WIFI_TYPE "STA" // Access point : "AP" pr Station (through router): "STA"

#define SECRET_SSID "Your wifi SSID"

#define SECRET_PASS "Your password"</b>

--> Modify (and then save) the file "arduino_secrets.h" with the Wi-Fi information. For sake of example, below we are showing the same network info we used in the demo example in Step 2 above:

<b>#define SECRET_WIFI_TYPE "STA" // Access point : "AP" pr Station (through router): "STA"

#define SECRET_SSID "Jones"

#define SECRET_PASS "test1234"</b>


--> The PetitCat project file in the Arduino IDE (which will be uploaded to the robot car) now has your Wi-Fi network information required to attached to the same network your laptop/desktop computer is running (and from which you will communicate with the robot car via your Python programs).

-------------------
-
-

Go to the Arduino IDE. Click 'File', 'Sketchbook', 'Osoyoo'.  Open the project "petitcat_arduino.ino" 

(Or, click 'File', 'Open Recent' and you may see "petitcat_arduino.ino" there already -- click it.)

--> In the Arduino IDE you will see one of the modules as being "Robot_define.h" -- click that Window.

In an early line you will see something like:

#define ROBOT_ID 0

It is important that the correct robot model is specified. Usually '0' is used for the default Osoyoo robot car.

Ok.... let's see if everything works....


Make sure the robot car is plugged into the USB port of your computer.

Click the green circle with the right-pointing arrow (which actually is the second circle in the left-hand upper corner) -- the Arduino code will automatically compile and upload to the Arduino board of the robot car.

Click Serial Monitor. (If no IP address is shown in the Serial Monitor when we run our code then go back to Part II to troubleshoot this problem.)

Note the IP Address shown in the Serial Monitor.

-
-

You need to have a working copy of Python on your laptop/desktop computer and some sort of programming environment to use it in. You may be using an advanced IDE such as Visual Studio IDE or PyCharm or a more streamlined development environment (e.g., such as Notepad++ operating in the terminal, which is what I am using). 

Tip: Do not download the latest version. It may not be fully stable, as well as dependencies creep into your project, the latest version of Python often is not compatible with older dependencies whose developers have not updated them yet. Download a recent, stable version of Python. At the time of writing, I have Python 3.11.4 running on my computer although at python.org the latest release is at the time of writing version 3.12.2 (considered stable) or  version 3.13 (newest version available). 


Go to https://github.com/OlivierGeorgeon/osoyoo/tree/master/tests  and copy the file "test_remote_control_robot.py" into your Python environment.

In my case I loaded this file into my Python development tool Notepad++ :

![testremote](testremote.png)

-
Before running a Python program take a look at it quickly. What will it do? Anything strange to the system? What about imports? Are there any imports requring installation of libraries from PyPI or an external library? The import's of socket, keyboard, sys and json all come from the standard library, so nothing special for us to do.

-
-

-The Arduino code was successfully compiled and uploaded to the robot car. 

-In the Serial Monitor you can see the IP address which the robot car is using to communicate via Wi-Fi.

-Ok.... now let's run the program test_remote_control_robot.py :

You need to provide the above IP Address to the Python code so it knows how to communicate via Wi-Fi with the PetitCat robot car.

For example, if the IP Address is 10.0.0.40 then at the command line write:

>python test_remote_control_robot.py 10.0.0.40

(Note: If you don't add the IP address to the command line, it might seem like the code works, and then asks you for the IP address. However, often it may not work properly. Thus, please enter the IP address on the command line like in the example above.)

Ok, let's try it out....

-

![connected](connected.png)

-

Success!!  Everything seems to run ok.

Now let's try it out. Unplug the robot car from the USB and put it down on the floor. Enter an '8' into the keyboard attached to the computer running the Python code. The car goes forward. Then enter a '2' -- the car goes backwards.  Let's try moving the servomechansim -- that works also. Success!!

Ok.... we know that the basic hardware, software (both Arduino level and Python level) and Wi-Fi connectivity all work. 

(If this does not work, then go back to Part 2 to troubleshoot any issues you may be having with your hardware, software or Wi-Fi environment.)

---------------

Note regarding forward and reverse directions of the wheels. You may have found that in section i (i.e., Lesson 5.2b Osoyoo software) above the wheels were turning in the opposite direction of the remote control arrows but were no sure of the arrows direction -- actually the wheels were turning in the opposite direction. However, in this section ii (i.e., controlling the robotic car with the Python program via Wi-Fi, the wheels appear to following the correct directions. That is fine.

See Part II for troubleshooting regarding the wheel direction, if there is a problem. However, if wheel direction with the Python program is correct, that is fine.

---------------


<p align="center">
 <img src="wifiworks.jpg" width="250" height="250">
</p>

-


<h1 style="font-size: 24px;">Step #3 -- Use the petitcat2.py Module to Interface Your AI/AGI Code with the Robotic Car" </h1>


Ok.... you have completed Step #2 above. 

Very important -- make sure all the hardware and software modules are working before we start venturing off into new advanced uses of the Robotic Car.  If you did not complete Step #2 then go back and complete it!! If you can't make the system do the basics above, then troubleshoot the problem.

(To do so you may have to go back to Part 2 or even Part 1 of the Easy-to-Read Documentation.) (If you don't have a technical background, e.g., MBA wanting to learn something about robotics/AI or you're a gifted high school student going through the project, then welcome to the world of engineering. Stuff sometimes doesn't work. You don't give up. You troubleshoot and rework the problem. Ok.... make sure Step #2 above works.)

In this section, we are going to take a baby step, and run Python code that lets you better (eventually) interface your AI/AGI project (if you have one; if not, no worries -- you can do one later or use code we will supply later) to the PetitCat project.

The C/C++ code is unchanged, i.e., the same "petitcat_arduino.ino" code is still saved on the robotic car and if your router's IP addresses have not changed since you tried out the car above in Step #2, then there is nothing do other than turn on the car. 

(However, if the Arduino code uploaded to the car has possibly changed then: Plug the USB into the car and your computer. Open up the Arduino IDE. Upload the "petitcat_arduino.ino" code to the car. Look at the Serial Monitor for the IP address to use. If there are any issues with these steps please see the previous Step #2 or for further troubleshooting the documentation in Part #2. However, if you just completed Step #2 then this should work without problem.)

Ok.... so the same Arduino code is running on the robot car. However, we need the new Python code:

Go to https://github.com/OlivierGeorgeon/osoyoo/tree/master/tests  and copy the file "petitcat2.py" to your Python environment. 

Now turn on the robotic car. Now in your Python environment (e.g., in Windows I am using the terminal and will show examples from there), run the program "petitcat2.py": 

Windows terminal:    >python petitcat2.py


The program will then ask for the IP address. It is the same address as before if you have not turned off the robotic car (i.e., 10.0.0.40 in the example above for my Wi-Fi). 

(Note: It is ok to give the IP address here -- it will work correctly. You don't have to type it at the command linke like in Step #2 above.) 

(Note: If you have reloaded the Arduino code then look at the serial monitor on the Arduino IDE to see what the IP address is.)


The demo program is self-explanatory and you can try it out.

Please see the screen capture of my Windows terminal to see what it should look like:

-

<p align="center">
 <img src="petitcatrun.png" width="1200" height="800">
</p>

-

This program seems very similar to the previous test_remote_control_robot.py, and indeed the actions and sensory inputs are. However, as we will see in the next section (i.e. next 'step' as they are called in this documentation), the code now largely consists of a Python class 'PetitCatController'. In the next section (i.e., 'step') we will explore how we can use class PetitCatController with other Python projects that want to interface with the robotic car.

-


<h1 style="font-size: 24px;">Step #4 --  Looking at the Code in the petitcat2.py Module" </h1>

-

Go to your Python IDE (i.e., where you can develop Python programs). If you look at the Python code for petitcat2.py, you see that this module provides a class "PetitCatController" to control the PetitCat robotic device, which by default is the robotic car.

The purpose is to ground your AI/AGI project in the real world by providing access to such embodiments.

The PetitCat project has a number of more advanced modules allowing, for example, active inference. These are discussed later.

This module, however, is to provide the basics of providing your AI/AGI project with an embodiment.

Summary of Module: It allows sending motor commands and receiving sensory inputs to/from the robotic device.

Nomenclature of saved files: petitcatN.py   e.g., petitcat2.py

This file will on its own allow your AI/AGI project access to a robotic device embodiment.

Example usage:

    Run the program from the command line, optionally providing the IP address as a command-line argument (or enter it later):
    
    python petitcat2.py <robot_ip>

    If no IP address is provided on the command line, the program will prompt the user with the updated message to input the IP address.
    
    You can find this IP address from the Arduino serial monitor after the USB cable is plugged into the device and Arduino
    code is downloaded (or already on the robotic device)
    (This IP address will be fetched automatically in future enhancements to the project.)

    Example motor command
    
    motor_code = input("Enter motor command: ")
    
    response = controller.motor_command(motor_code)
    
    print("Motor Command Response:", response)
    

    Example sensory input request
    
    sensory_system = input("Enter sensory system (ultrasound/ir): ")
    
    response = controller.sensory_input(sensory_system)
    
    print("Sensory Input Response:", response)

-
-

In Step #3 above we utilized this class using the default demo code in "petitcat2.py":

-

<p align="center">
 <img src="classcode.png" width="800" height="800">
</p>

-

Let's take a look at the demonstration code.

It starts off by instantiating the PetitCatController class with an instance called "controller".

Then the demo code goes into While-loop, which requires the user to input 'exit' to leave.

First in the loop there is:  response = controller.motor_command(motor_code)

"motor_code" is a value the user enters and which will be send to the robotic car. The codes are similar to the ones used in the above sections. For example, if you enter '2' the wheels of the robotic car will spin backwards.

Note that we get a response put into the variable "response" from controller.motor_command().

The next item in the While loop is: response = controller.sensory_input(sensory_system)

The requested sensory system will send back a response.

Examine the code for more details.

Now try to write a module of your own that allows the car to trace out the letter "H" using the PetitCatController() class.

(Or you can download such a Python program from: Go to https://github.com/OlivierGeorgeon/osoyoo/tree/master/tests  and copy the file "sillyHdemo.py" to your Python environment.)

Did you try out your code?

If you want to look at sillyHdemo.py code, let's consider the start of the program:

<p align="center">
 <img src="silly.png" width="700" height="300">
</p>


Note that we have to import "PetitCatController" class now from the module petitcat2.py.

Not shown in the code segment above are the lines at the end of the code. Let's show it here:

<p align="center">
 <img src="mainsilly.png" width="700" height="300">
</p>


Note that we instantiate the class PetitCatController with "controller" and we pass "controller" into the function trace_h(controller).

The function trace_h(ctrl=controller) then calls forward, backward, right and left turn functions to trace out the letter H by the robot car.

If you look at the code above you see the code for the function move_foward(ctrl=controller, duration_in_seconds).

This function uses ctrl.motor_command() and a value of "8" is passed as parameter to go forwards. Other functions for going backwards, left, right, etc are similar but pass different values.


-


<h1 style="font-size: 24px;">Step #5 --  Considering the Return Data from the Robotic Car" </h1>
-

Ok.... run petitcat2.py.

(Which means:

#1 -- Plug the USB into the car and your computer. Open up the Arduino IDE. Upload the "petitcat_arduino.ino" code to the car. (Not necessary if this code is already running on your robotic car's Arduino board.)

#2 -- Look at the Serial Monitor for the IP address to use. (Not necessary if car was not powered off and your Wi-Fi remains stable.)

#3 -- Go to https://github.com/OlivierGeorgeon/osoyoo/tree/master/tests  and copy the file "petitcat2.py" to your Python environment. (Not necessary if this file is already in your Python environment.)

#4 -- Now turn on the robotic car. Now in your Python environment (e.g., in Windows I am using the terminal and will show examples from there), run the program "petitcat2.py": 

Windows terminal:    >python petitcat2.py    )

If you enter the code '2' so that the robot car goes backwards, note that the following sensory data appears as shown in the screenshot below. (Note that the PetitCat project grew out of a strong sense of grounding as well as active inference where there is emphasis on the action-sense cycle to make sense of the world, rather than the stereotypical sense-action cycle of other artificial systems.)

---------------------------
Small theoretical divergence here (optional to read):

Traditional engineered systems often follow a sense-action cycle, which is more reactive. The system senses the environment, processes the data, and then takes an action based on that sensory input.

In the context of active inference, the action-sense cycle means that actions are taken to reduce prediction errors. The PetitCat system is proactive, using actions to gather data that will refine its understanding of the environment.

Active inference is a theory from neuroscience and cognitive science, primarily associated with the work of Karl Friston. It posits that organisms (or systems) actively try to minimize the difference between their predictions about the world and the actual sensory data they receive.

This involves both perception (updating beliefs based on sensory input) and action (changing the environment to align sensory input with predictions).

In the context of active inference, the action-sense cycle means that actions are taken to reduce prediction errors. The system is proactive, using actions to gather data that will refine its understanding of the environment.

In the context of traditional engineering systems (i.e., the courses you may have taken in university as part of an engineering degree) systems often follow a sense-action cycle, which is more reactive. The system senses the environment, processes the data, and then takes an action based on that sensory input.

Thus, much of the code surrounding the PetitCat project tends to be an action-sense cycle. HOWEVER.... yes, you can easily change this to a traditional sense-action cycle, and we do indeed do this in later Parts of the documentation for some small projects.

---------------------------


Ok..... se we enter '2' for a motor command, the robot goes backwards, and we see the following response from this motor command:


<p align="center">
 <img src="statussig.png" width="700" height="300">
</p>


What do these parameters mean?

clock -- counting the number of action-sense cycles and which one this is

action -- the action value entered, which was a '2' in the example above

duration1 -- how many milliseconds the action lasted for, which was about 1 second the car was going backwards

duration -- the total duration of this 'clock cycle', which was about 1.3 seconds here

head_angle -- the head angle of the ultrasonic sensor in + or - degrees from straight ahead, so, the -50 degrees shown is 50 degrees to the right of the robot with 0 degrees being straight ahead

echo_distance -- the distance in mm from which the ultrasonic echo occurred, so the -50 degrees echo occurred 400 mm, i.e., 40 cm, away

floor and status -- if there is a transition in the floor color from reflecting to a black line or area you will see '1's returned; these will be discussed in more detail later. Generally if no change there will be 0 returned, 1 if a change to the right, 2 if a change to the left, and 3 if a change to both the right and the left

The motor commands which you can enter are as follows:

'1' - turn left

'2' - go backwards

'3' - turn right

'4' - swipe left (omnidirectional wheels allow the robot car to actually go left, i.e., not turn left but move left)

'6- - swipe right

'8' - go forwards

'-' - ultrasonic scan

Let's try the '-' command. Perhaps put an object in front of the robot. I just put a glass in front of the robot. At the prompt "Enter motor command" I then entered '-'  (i.e., just the dash without the quotes, of course) and pressed Enter. This motor command is to move the servomechanism holding the ultrasonic transducer in an arc. You then see something like this returned as the response:  

{"clock":20,"action":"-","duration1":1118,"head_angle":0,"echo_distance":37,"floor":0,"duration":1426,"echos":{"-90":417,"-60":570,"-30":51,"0":37,"30":65,"90":997},"status":"0"}'

Note that there are echos at 90 degrees to the right, 60 degrees to the right, 30 degrees to the right, 0 degrees straight ahead (the glass about 4 cm away), 30 degrees to the left, 60 degrees to the left and 90 degrees to the left.

So... you actually can get your sensory information here via a motor command. 

(We will discuss the Sensory Input Response possible input parameters and the response later.)


-
-

<h1 style="font-size: 24px;">Step #6 -- Adding an LLM to the PetitCat Project </h1>

This section about adding a Large Language Model is optional reading, as there will be an entire Part dedicated to the this subject further in the documentation. However, we have tried to cover all the basics of the PetitCat Project, i.e., the robotic embodiment (which is a robotic car but could be virtually any robotic embodiment controlled by an Arduino board), the lower level C/C++ code compiled by the Arduino IDE into machine code to run a microcontroller which controls the robotic embodiment, the basic electronics and mechatronics of the robotic embodiment and Arduino board interface, the Wi-Fi communication with the Arduino board, and finally the Python code which communicates with the Arduino baord and which can be used with your AI/AGI Python code to allow grounding (i.e., essentially interfacing) with the robotic embodiment.

Most readers will be familiar with large language models at this time, e.g., ChatGPT, and many others, of course. A large language model (LLM) is a type of artificial intelligence (AI) model designed to understand and generate human language. These models are trained on vast amounts of text data and are capable of performing a wide range of language-related tasks, such as text generation, translation, summarization, and answering questions. 

Below we will interface an LLM API, one of the ChatGPT API's (it may change from the time of the writing) with the PetitCat project. We will continue with the source code of petitcat2.py and modify it, and save the new Python file interfaced with the LLM API as petitcatllm.py

The file petitcatllm.py can be downloaded from the PetitCat project pages at GitHub.

Go to https://github.com/OlivierGeorgeon/osoyoo/tree/master/tests  and copy the file "petitcatllm.py" to your Python environment.

If you look at the code you will see that the program starts off by importing a library that abstracts away many of the details of interfacing with LLM API's, and that we are using the library modules for OpenAI's LLM APIs:

<p align="center">
 <img src="importopenai.png" width="700" height="300">
</p>

In the constants section of the code you can see a number of the prompts which we will use with the LLM. Some of these prompts are for solving a travelling salesperson problem and for solving a compositionality problem, which will be used as comparisons when we interface the PetitCat project to a cognitive architecture, in later Parts of the documentation.

Looking at the initializations section of the code you can see the details how we initialize the OpenAI LLM API. Note that the licensed key required for using this API is stored in the host computer's environmental variables, so as to prevent needing to disclose them publicly in the Python source code.

Many of the LLM APIs available now do require paid licenses, although the fees are modest monthly ones. However, better performing open source free LLM API's are starting to emerge at the time of this writing, and hopefully can be used with future versions of the PetitCat Project. Thus, in order to try out the code below, you would need a paid subscription to OpenAI's ChatGPT product (i.e., the lowest cost consumer-level subscription is fine -- it is not very expensive and can be cancelled after one month) to actually use the code below with the LLM.




PENDING

-

<h1 style="font-size: 24px;">Step #7 -- Installing PetitCatMain1.py </h1>

We will now install "PetitCatMain1.py" which will demonstrate some of the grid cell features of the PetitCat project.


PENDING

Perhaps also cloning of directory structure, perhaps introduce venv virtual environments?



-


-


.....

--
--




<p align="center">
 <img src="successpic.png" width="70" height="70">
</p>

-


<p align="center">
 <img src="altlogo.png" width="470" height="470">
</p>


-
-


end of document
****
##




